# front-end-ASIC-design-LMM-tool-using-RAG
Automated Front-End VLSI Design tool. Uses an LLM-RAG pipeline to transform high-level design specifications into PPA-optimized, synthesizable RTL IP blocks (Verilog/VHDL). Features an iterative verification loop for bug correction and quality assurance.
# ğŸ¤– Automated Front-End VLSI Design AI Tool using LLM RAG

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository hosts a cutting-edge, end-to-end AI tool that automates the front-end VLSI (Very Large-Scale Integration) design flow. It utilizes a **Retrieval-Augmented Generation (RAG) pipeline** powered by a Large Language Model (LLM) to convert high-level functional specifications into **synthesizable, PPA-optimized Register-Transfer Level (RTL) IP blocks** with a closed-loop verification process.

## âœ¨ Key Features

* **Spec-to-RTL Generation:** Automatically translates natural language specifications (architecture, functional requirements, protocols) into Verilog/VHDL code, including complex Finite State Machines (FSMs) and Testbenches (TB).
* **PPA Optimization:** The LLM is conditioned to generate RTL focused on achieving the best balance of **Power, Performance, and Area (PPA)** efficiency.
* **Verification-in-the-Loop:** Simulation results (waveforms, coverage logs) are fed back to the LLM to **iteratively correct and refine** the generated RTL until it fully matches the specification.
* **Contextual Accuracy (RAG):** The **RAG engine** grounds the generation by retrieving relevant information from a dedicated **Knowledge Base** (RTL libraries, protocols, reference guides), significantly reducing LLM "hallucinations."
* **Web Interface:** A user-friendly React frontend for file upload, parameter configuration, execution, and output visualization.

***

## ğŸ’¡ VLSI Design Flow (RAG Pipeline)

The system operates in a continuous, iterative loop to ensure functional correctness and quality standards. 

| Step | Component | Description |
| :--- | :--- | :--- |
| **1. Input & Parsing** | **NLP Parser** (`file_parser.py`) | Upload specification documents and use NLP to extract structured constraints. |
| **2. Retrieval** | **RAG Engine** (`rag_service.py`) | Query the **Knowledge DB** (`vector_db/`) to retrieve relevant golden RTL and reference protocols. |
| **3. Generation** | **LLM Spec-to-RTL** (`rtl_generator.py`) | LLM generates **RTL (Verilog/VHDL)** and **Testbench/VIP** focused on **PPA efficiency**. |
| **4. Verification** | **Post-Processing & Sim** | RTL is checked (Lint, Synthesis Check, STA, CDC) and simulated (UVM, FV). Generates **Waveforms** and **Coverage Logs**. |
| **5. Correction** | **Iterative Loop** | **Verification results are fed back** to the LLM for automated bug correction until spec match is achieved. |
| **6. Final Output** | **Synthesizable IP** | The stable, verified, and PPA-optimized **Synthesizable RTL IP block** is produced. |

***

Markdown

# ğŸ¤– Automated Front-End VLSI Design AI Tool using LLM RAG

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository hosts a cutting-edge, end-to-end AI tool that automates the front-end VLSI (Very Large-Scale Integration) design flow. It utilizes a **Retrieval-Augmented Generation (RAG) pipeline** powered by a Large Language Model (LLM) to convert high-level functional specifications into **synthesizable, PPA-optimized Register-Transfer Level (RTL) IP blocks** with a closed-loop verification process.

## âœ¨ Key Features

* **Spec-to-RTL Generation:** Automatically translates natural language specifications (architecture, functional requirements, protocols) into Verilog/VHDL code, including complex Finite State Machines (FSMs) and Testbenches (TB).
* **PPA Optimization:** The LLM is conditioned to generate RTL focused on achieving the best balance of **Power, Performance, and Area (PPA)** efficiency.
* **Verification-in-the-Loop:** Simulation results (waveforms, coverage logs) are fed back to the LLM to **iteratively correct and refine** the generated RTL until it fully matches the specification.
* **Contextual Accuracy (RAG):** The **RAG engine** grounds the generation by retrieving relevant information from a dedicated **Knowledge Base** (RTL libraries, protocols, reference guides), significantly reducing LLM "hallucinations."
* **Web Interface:** A user-friendly React frontend for file upload, parameter configuration, execution, and output visualization.

***

## ğŸ’¡ VLSI Design Flow (RAG Pipeline)

The system operates in a continuous, iterative loop to ensure functional correctness and quality standards. 

| Step | Component | Description |
| :--- | :--- | :--- |
| **1. Input & Parsing** | **NLP Parser** (`file_parser.py`) | Upload specification documents and use NLP to extract structured constraints. |
| **2. Retrieval** | **RAG Engine** (`rag_service.py`) | Query the **Knowledge DB** (`vector_db/`) to retrieve relevant golden RTL and reference protocols. |
| **3. Generation** | **LLM Spec-to-RTL** (`rtl_generator.py`) | LLM generates **RTL (Verilog/VHDL)** and **Testbench/VIP** focused on **PPA efficiency**. |
| **4. Verification** | **Post-Processing & Sim** | RTL is checked (Lint, Synthesis Check, STA, CDC) and simulated (UVM, FV). Generates **Waveforms** and **Coverage Logs**. |
| **5. Correction** | **Iterative Loop** | **Verification results are fed back** to the LLM for automated bug correction until spec match is achieved. |
| **6. Final Output** | **Synthesizable IP** | The stable, verified, and PPA-optimized **Synthesizable RTL IP block** is produced. |

***

## ğŸ“ Repository Structure

The project is a full-stack application with a Python/FastAPI backend, a dedicated RAG knowledge base, and a React/Vite frontend.

front-end-ASIC-design-LMM-tool-using-RAG

```bash
vlsi-llm-rag/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
|
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ services/  (Core LLM/RAG/VLSI Logic)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rtl_generator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vip_generator.py
â”‚   â”‚   â”‚   â””â”€â”€ file_service.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ file_parser.py
â”‚   â”‚       â””â”€â”€ prompts.py
|
â”œâ”€â”€ knowledge_base/  (Retrieval-Augmented Data)
â”‚   â”œâ”€â”€ specs/
â”‚   â”œâ”€â”€ protocols/
â”‚   â””â”€â”€ vector_db/
|
â”œâ”€â”€ frontend/ (React/Vite Application)
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.jsx
â”‚       â”œâ”€â”€ App.jsx
â”‚       â”œâ”€â”€ App.css
â”‚       â”œâ”€â”€ components/ (Reusable UI)
â”‚       â”‚   â”œâ”€â”€ FileUpload.jsx
â”‚       â”‚   â”œâ”€â”€ CodeViewer.jsx
â”‚       â”‚   â”œâ”€â”€ StatusPanel.jsx
â”‚       â”‚   â””â”€â”€ RequirementsForm.jsx
â”‚       â””â”€â”€ pages/ (Main Views)
â”‚           â”œâ”€â”€ Home.jsx
â”‚           â”œâ”€â”€ Upload.jsx
â”‚           â”œâ”€â”€ Generate.jsx
â”‚           â””â”€â”€ Outputs.jsx
|
â””â”€â”€ examples/
    â”œâ”€â”€ axi4_lite/
    â”‚   â”œâ”€â”€ spec.txt
    â”‚   â””â”€â”€ requirements.md
    â””â”€â”€ uart/
        â”œâ”€â”€ spec.txt
        â””â”€â”€ requirements.md
```

***

## ğŸš€ Getting Started

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/OWNER/front-end-ASIC-design-LMM-tool-using-RAG.git](https://github.com/OWNER/front-end-ASIC-design-LMM-tool-using-RAG.git)
    cd front-end-ASIC-design-LMM-tool-using-RAG
    ```
2.  **Setup Environment Variables:**
    ```bash
    cp .env.example .env
    # Edit the .env file with your LLM API key (e.g., GEMINI_API_KEY=...)
    ```
3.  **Run with Docker (Recommended):**
    ```bash
    # Build and run the entire stack (backend, frontend, vector db)
    docker-compose up --build
    ```

The application will be accessible at `http://localhost:3000`.

![VLSI RAG Design Flow Diagram](assets/Automated%20front%20end%20VLSI%20design%20AI%20tool%20using%20LLM%20RAG.png)

## ğŸ“ Repository Structure

The project is a full-stack application with a Python/FastAPI backend, a dedicated RAG knowledge base, and a React/Vite frontend.
